{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6fda38-3d00-4681-afa5-cc16981ca8d2",
   "metadata": {},
   "source": [
    "### Telegram Chatbot for Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009c83a-9306-47d7-829b-c0c2617efbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the chatbot as following per the link:\n",
    "# t.me/fin_sandbox_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0340d8b-3926-454e-a876-ad7dba9f935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katsiaryna/workspace/BelHard_ML_NN_PROF_LEVEL_2025/DSP_W3/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n",
      "2026-01-07 16:33:12,323 - telegram.ext.Application - INFO - Application started\n",
      "Batches: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 13.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "import logging\n",
    "import os\n",
    "\n",
    "###########################\n",
    "# Documents and Embeddings\n",
    "###########################\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model for embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load documents\n",
    "loader = TextLoader('TSLA_description.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = [embedding_model.encode(chunk.page_content) for chunk in chunks]\n",
    "embeddings_np = np.array(embeddings)\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# Create LangChain vectorstore using HuggingFace embeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings_model)\n",
    "\n",
    "###########################\n",
    "# Retrieval and LLM Chain\n",
    "###########################\n",
    "\n",
    "# Use a text2text-generation model (Flan-T5 small works well)\n",
    "gen_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\"\n",
    ")\n",
    "\n",
    "# Wrap the pipeline in HuggingFacePipeline\n",
    "llm_chain = HuggingFacePipeline(pipeline=gen_pipeline)\n",
    "\n",
    "# Create RetrievalQA chain with the top 3 chunks being selected - short most relevant responses\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})  # Top 3 chunks\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_chain,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# # Create RetrievalQA chain - for longer answers\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm_chain,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vectorstore.as_retriever()\n",
    "# )\n",
    "\n",
    "###########################\n",
    "# Telegram Bot Handler\n",
    "###########################-\n",
    "\n",
    "# # /start command\n",
    "# async def start(update: Update, context: CallbackContext) -> None:\n",
    "#     await update.message.reply_text(\"Hello! Send me any question about TSLA and I'll try to answer it.\")\n",
    "\n",
    "# Handle user questions\n",
    "async def handle_message(update: Update, context: CallbackContext) -> None:\n",
    "    query = update.message.text\n",
    "    response = qa_chain.run(query)\n",
    "    await update.message.reply_text(response)\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "# Retrieval from API\n",
    "###########################\n",
    "import logging\n",
    "import nest_asyncio  # Import nest_asyncio\n",
    "import asyncio\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "import yfinance as yf\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set httpx logging level to CRITICAL to suppress almost everything\n",
    "logging.getLogger(\"httpx\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API tokens\n",
    "#openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "telegram_api_key = os.getenv('TELEGRAM_API_KEY')\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up logging to help with debugging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Function to fetch stock information\n",
    "# def get_stock_info(ticker):\n",
    "#     try:\n",
    "#         stock = yf.Ticker(ticker)\n",
    "#         info = stock.info\n",
    "#         price = info.get('currentPrice', 'No data available')\n",
    "#         market_cap = info.get('marketCap', 'No data available')\n",
    "#         return f\"Price: ${price}\\nMarket Cap: {market_cap}\"\n",
    "#     except Exception as e:\n",
    "#         return \"Error fetching stock data. Please try again later.\"\n",
    "\n",
    "def get_stock_info(ticker, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            stock_info = stock.info\n",
    "            price = stock_info.get(\"currentPrice\", \"No data available\")\n",
    "            return price\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1}: Error fetching data for {ticker}: {e}\")\n",
    "            time.sleep(delay)  # Wait before retrying\n",
    "    return \"Error fetching stock data after multiple attempts.\"\n",
    "\n",
    "# Command to start the bot\n",
    "async def start(update: Update, context: CallbackContext) -> None:\n",
    "    await update.message.reply_text('Hello! I am your finance bot. Ask me about stock prices by typing \"start/ AAPL\" to find Apple market price. Otherwise ask a question about Tesla.')\n",
    "\n",
    "# Handler to process stock symbol queries\n",
    "async def get_stock(update: Update, context: CallbackContext) -> None:\n",
    "    if context.args:\n",
    "        ticker = context.args[0].upper()  # Get stock ticker symbol (e.g., AAPL)\n",
    "        stock_info = get_stock_info(ticker)\n",
    "        await update.message.reply_text(f\"The current stock price is: {stock_info}\")\n",
    "    else:\n",
    "        await update.message.reply_text(\"Please provide a stock ticker (e.g., AAPL).\")\n",
    "\n",
    "\n",
    "###########################\n",
    "# Main Application\n",
    "###########################\n",
    "\n",
    "# Main function to start the bot\n",
    "async def main() -> None:\n",
    "    # Get your bot's API token from BotFather\n",
    "    token = telegram_api_key\n",
    "\n",
    "    # Create an Application object and pass in the bot's API token\n",
    "    application = Application.builder().token(token).build()\n",
    "\n",
    "    # Register the start command handler\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "\n",
    "    # Register a handler for stock price queries\n",
    "    application.add_handler(CommandHandler(\"stock\", get_stock))\n",
    "\n",
    "    # Register a handler for all messages (in case someone sends a message without a command)\n",
    "    #application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, get_stock))\n",
    "\n",
    "    # ----- langchain q-a integration--------------\n",
    "    # Register handlers: the q-a feature\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
    "\n",
    "    # Start the bot (non-blocking)\n",
    "    await application.run_polling()\n",
    "\n",
    "# Use the existing event loop instead of asyncio.run()\n",
    "if __name__ == '__main__':\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()  # Necessary for running async in Jupyter or some IDEs\n",
    "    import asyncio\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013912a-4f1f-4819-81d7-63a1284cd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Download Company Description from Yahoo Finance and Saved as Txt File\n",
    "\n",
    "\n",
    "# import yfinance as yf\n",
    "# import os\n",
    "\n",
    "# # Function to fetch and save company description from Yahoo Finance\n",
    "# def fetch_and_save_description(ticker):\n",
    "#     try:\n",
    "#         stock = yf.Ticker(ticker)\n",
    "#         company_info = stock.info\n",
    "#         description = company_info.get(\"longBusinessSummary\", \"No description available.\")\n",
    "        \n",
    "#         # Save the description to a .txt file\n",
    "#         with open(f\"{ticker}_description.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "#             file.write(description)\n",
    "        \n",
    "#         print(f\"Description for {ticker} saved to {ticker}_description.txt\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "\n",
    "# # Fetch and save descriptions for multiple companies\n",
    "# company_tickers = [\"AAPL\", \"TSLA\", \"GOOGL\"]\n",
    "# for ticker in company_tickers:\n",
    "#     fetch_and_save_description(ticker)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
